[ { "title": "Gradle 基础学习笔记", "url": "/posts/Start-with-Gradle/", "categories": "构建工具", "tags": "笔记, 挖坑", "date": "2021-06-02 01:00:00 +0800", "snippet": "介绍gralde 是一个 开源的自动化构建工具，设计的初衷就是为了足够灵活，来满足几乎所有软件的构建需求。并且具有以下的功能： 高性能 只编译需要编译的部分（因为 task 的输入和输出变动），甚至可以在不同的机器上利用 build cache（有共享 cache 的条件下） 基于 JVM 熟悉java 的人很轻松就能学会 基于约定实现 gradle 借鉴了 maven...", "content": "介绍gralde 是一个 开源的自动化构建工具，设计的初衷就是为了足够灵活，来满足几乎所有软件的构建需求。并且具有以下的功能： 高性能 只编译需要编译的部分（因为 task 的输入和输出变动），甚至可以在不同的机器上利用 build cache（有共享 cache 的条件下） 基于 JVM 熟悉java 的人很轻松就能学会 基于约定实现 gradle 借鉴了 maven，并建立了基于约定实现的通用项目很容易就能够构建，比如 java 项目，并且 这些实现也可以很轻松就被自定义，只需要遵循实现约定 可扩展性 可以轻松扩展 gradle 来自定义 tasks 或者 build model ，例如： 安卓的构建过程就添加了很多新的构建类型和风格 IDE suppoort 很多主流 IDE 可以引入 gradle 项目以便与与之交互，并且 gradle 还可以根据不同的 IDE 产生不同的 IDE 支持配置，例如ES 的 ./gradlew idea 命令就可以产生 idea 的配置文件 Insight build scan and share 可以让构建过程能分享给其他人，与其他人交流并发现问题关键点gradle 是一个通用型构建工具，而不只是为了构建 Java application核心模型基于 tasksgradle 的构建模型是基于tasks 的 DAG， 意味这 构建的本质是 根据配置文件 将很多 task 基于依赖关系组合起来。 一旦 DAG 创建完成之后 gradle 会根据 DAG 来确定任务的执行先后顺序。tasks 由以下三个组成： Action – 此 task 需要做的实际操作，比如：copy 文件和编译源码 inputs – task 的输入，比如配置文件，环境变量等 outputs – task 需要创建的文件目录和需要修改的文件等等以上的提到的三个元素都不是必须的，task 依赖于本身需要做什么操作。gradle 的标准task 就都没有 任何 action，标准task 仅仅是聚合起来成为一个 构建约定。需要注意的点是: gradle 基于tasks的模型使得 gradle 的增量编译很稳定和准确，除非真的需要 清除所有构建中间文件，否则尽量不要 做 clean 动作Gradle 有几个固定的构建阶段 Initialization – 设置build 环境，确定 哪些 project 需要加入进来 Configuation – 根据用户想要运行的 task 装配和配置 build 的 task DAG ，然后确定哪些 task 需要运行和运行顺序 Execution – 运行 task 以上几个阶段跟 maven 的phase 不一样，maven 利用 phase 将 build 分成不同的 阶段，更像 gradle 的 各种task，但是又缺少了灵活性gradle 的扩展方式不止一种想要 gradle 内置所有的构建逻辑几乎是不可能的，大部分的构建应用都需要许多自定义逻辑来处理 自定义 task type - 通过把 源码放进 buildSrc 文件夹中或者 plugin 的方式可以自定义 task type 自定义 task action - 通过 doFist() 和 doLast() 方法 在 project 和 tasks 中自定义 额外的 properties 自定义约定 - 通过 plugin 来自定义 约定 像 Java build 一样 自定义模型 - 大部分语言都会自定义模型来让构建更有效和更快捷构建脚本操作 API将 Gradle 的构建脚本视为可执行代码很容易，因为它们就是这样。 但这是一个实现细节：精心设计的构建脚本描述了构建软件所需的步骤，而不是这些步骤应该如何完成工作。 这是自定义任务类型和插件的工作。有一种常见的误解，认为 Gradle 的强大功能和灵活性来自它的构建脚本是代码这一事实。 这与事实相去甚远。 正是底层模型和 API 提供了强大的功能。 正如我们在最佳实践中建议的那样，您应该避免在构建脚本中放置过多的命令式逻辑（如果有的话）与 Maven 比较编译性能方面gradle 和 maven 两种构建系统在实现上有着本质的区别，正如上文所述，gradle 是基于task 的 DAG，各种task 根据不同的职能做不同的事情；然而 maven 是基于线性的固定 phase 的模型，在maven构建的过程中，goals 只是附加到 项目的 phase 上，goals 和 gradle 的task 相类似。在性能方面：maven 和gradle 都可以并行编译，但是 gradle 可以在初次编译之后进行 增量编译，大大减少编译的时长。并且 gradle 还具有以下特点可以加快编译的速度： java class 级别的 增量式变异 Java 项目的 Compile avoidance 增量子任务api 的应用 编译守护进程来加速编译管理依赖方面Gradle 和 Maven 都可以处理动态和传递依赖项，使用第三方依赖项缓存，并读取 POM 元数据格式。您还可以通过中央版本控制定义声明库版本并强制执行中央版本控制。两者都从他们的工件存储库下载传递依赖项。 Maven 有 Maven Central，而 Gradle 有 JCenter，您也可以定义自己的私人公司存储库。如果需要多个依赖项，Maven 可以同时下载它们。然而，Gradle 在 API 和实现依赖以及本质上允许并发安全缓存方面胜出。它还保留存储库元数据以及缓存的依赖项，确保使用相同缓存的两个或多个项目不会相互覆盖，并且它具有基于校验和的缓存并且可以与存储库同步缓存。此外，Gradle 与 IVY 元数据兼容，允许您定义自定义规则来为动态依赖项指定版本，并解决版本冲突。这些在 Maven 上不可用。同时，gradle 在管理依赖方面也有很多新功能可以使用： 兼容库的替换规则的使用 ReplacedBy 规则的使用 更好的元数据解析 使用外部依赖动态替换项目依赖的能力，反之亦然gradle 在兼容 IDE 方面也更加灵活，可以根据不同的 IDE 生成不同的配置文件，让用户选择更加方便。总结：就执行模型而言，两者都有任务组和描述。两者都使您能够仅构建指定的项目及其依赖项。然而，Gradle 有一个完全可配置的 DAG，而使用 Maven，一个目标只能附加到另一个目标。多个目标采用有序列表的形式。 Gradle 还允许任务排除、传递排除和任务依赖推断。 Gradle 还具有用于任务排序和终结器等的高级功能。管理构建基础设施是 Gradle 的另一个强项，因为它使用接受自动配置的包装器，而对于 Maven，您需要有一个扩展来支持自配置构建。 Gradle 还使您能够配置基于版本的构建环境，而无需手动设置这些环境。并且 gradle 还允许自定义如何分发应用。Demo 项目参照 samples/sample_building_java_applications参考 gradle user guide gradle vs maven gradle vs maven 2" }, { "title": "Java interface", "url": "/posts/Java-Interface/", "categories": "", "tags": "", "date": "2021-06-02 00:00:00 +0800", "snippet": "", "content": "" }, { "title": "后端研发日志记录规范", "url": "/posts/log-conduct/", "categories": "笔记", "tags": "总结", "date": "2020-07-02 01:00:00 +0800", "snippet": "背景 日志：记录程序的运行轨迹，方便查找关键信息，也方便快速定位解决问题。随着公司发展，后端项目app的数量 越来越多，排查问题的复杂度越来越高，需要对日志的格式统一规划，便于后续日志收集分析报警。日志的作用（WHY） 问题追踪： 辅助排查和定位线上问题，优化程序运行性能。 状态监控： 通过日志分析，可以监控系统的运行状态。 安全审计： 审计主要体现在安全上，可以发现非授权的操作。技...", "content": "背景 日志：记录程序的运行轨迹，方便查找关键信息，也方便快速定位解决问题。随着公司发展，后端项目app的数量 越来越多，排查问题的复杂度越来越高，需要对日志的格式统一规划，便于后续日志收集分析报警。日志的作用（WHY） 问题追踪： 辅助排查和定位线上问题，优化程序运行性能。 状态监控： 通过日志分析，可以监控系统的运行状态。 安全审计： 审计主要体现在安全上，可以发现非授权的操作。技术选型经过调研，公司目前所有后端java 应用都是spring-boot 技术栈，而spring-boot的底层日志依赖关系如下图所示：且，logback是 slf4j的默认实现，性能比log4j好很多,所以 后端统一选择用logback作为日志记录依赖。 使用 lombok 插件增强添加 log 变量记录规范 (HOW)记录时机当符合以下情况时，需要选择合适的级别记录日志： 无法处理的 RuntimeException,结合实际情况选择 warn 级别或 error级别 执行流程不符合业务流程，比如：参数不正确，类型不正确和返回值不在预期范围内等。选择 Error 或 info 级别 系统关键角色，组件核心动作： 比如服务之间的交互，数据库增删改等需要记录 info级别日志。 常规初始化： 系统初始化的关键参数等，需要记录info级别日志。如何记录（格式规范）结合公司实际情况，日志记录应包含以下信息： 日志时间（精确到毫秒） 日志级别 应用名称 - 项目名称 调用链标识（可选）- 唯一字段 业务标识 线程名称 记录器名称（class名方法名） 日志消息 异常栈（可选）日志文件名规范当前正在写入的日志文件名：&lt;log-level&gt;.log已经滚入历史的日志文件名：&lt;log_level&gt;.log.&lt;yyyy-MM-dd&gt;禁止项 禁止使用 System.out/error 记录 禁止出现 e.printStackTrace() 禁止线上环境 出现 debug 日志 禁止循环中打印日志日志配置文件和工具配置文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!--读取spring 配置--&gt; &lt;springProperty scope=\"context\" name=\"logPath\" source=\"logging.file.path\" defaultValue=\"logs\"/&gt; &lt;springProperty scope=\"context\" name=\"appName\" source=\"spring.application.name\" defaultValue=\"ZL-PROJECT\"/&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;!--配置--&gt; &lt;property name=\"appName\" value=\"${appName}\"/&gt; &lt;!--系统环境变量配置--&gt; &lt;property name=\"log.outside.level\" value=\"DEBUG\"/&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} [%contextName][bizId:%X{bizId}][%thread] %-5level %logger{50} [trackId:%X{trackId}] - %msg%n\" /&gt; &lt;contextName&gt;${appName}&lt;/contextName&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN} &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"ERROR\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt; ${logPath}/error.log &lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;${logPath}/bak/error.log.%d{yyyy-MM-dd}&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}-%caller{2}&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt;&lt;!-- 只打印错误日志 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${logPath}/info.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;${logPath}/bak/info.log.%d{yyyy-MM-dd}&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt;&lt;!-- 只打印INFO日志 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"DEBUG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt; ${logPath}/debug.log &lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;${logPath}/bak/debug.log.%d{yyyy-MM-dd}&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt;&lt;!-- 只打印DEBUG日志 --&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 测试环境+开发环境. 多个使用逗号隔开. --&gt; &lt;springProfile name=\"test\"&gt; &lt;logger name=\"org.springframework.web\" level=\"INFO\"/&gt; &lt;logger name=\"com.jizhang.platform\" level=\"INFO\"/&gt; &lt;logger name=\"com.ibatis\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.common.jdbc.SimpleDataSource\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.common.jdbc.ScriptRunner\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.Connection\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.Statement\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.jizhang.platform.mapper\" level=\"${log.outside.level}\"/&gt; &lt;/springProfile&gt; &lt;!-- 生产环境. --&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"org.springframework.web\" level=\"ERROR\"/&gt; &lt;logger name=\"com.jizhang.platform\" level=\"INFO\"/&gt; &lt;logger name=\"com.ibatis\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.common.jdbc.SimpleDataSource\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.common.jdbc.ScriptRunner\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.Connection\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.Statement\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"${log.outside.level}\"/&gt; &lt;logger name=\"com.jizhang.platform.mapper\" level=\"${log.outside.level}\"/&gt; &lt;/springProfile&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"STDOUT\"/&gt; &lt;appender-ref ref=\"ERROR\"/&gt; &lt;appender-ref ref=\"INFO\"/&gt; &lt;appender-ref ref=\"DEBUG\"/&gt; &lt;/root&gt;&lt;/configuration&gt;配置文件使用 将上述中的 logback-spring.xml 中的内容复制到项目 Resource 目录下，命名为： logback-spring.xml 在 spring properties中指定以下配置 logging.config=classpath:logback-spring.xml 在 spring properties 配置文件中指定log 文件输出目录(绝对地址),默认为项目 jar包 执行目录，示例如下 logging.file.path=/var/log/{appName} 配置 appName在spring property 文件中指定spring.application.name 属性，logback 配置文件中配置了 contextName为 spring.application.name 调用链表标识在需要 输出 调用链标识的时候 配置时，使用 org.slf4j.MDC定义trackId字段，具体可参考下面代码 MDC.put(\"trackId\",\"trackId\"); ‘trackId’： 可以认为是方法调用过程中的唯一不变的字段，比如：userId,或者操作的字段id,或者接到的请求跟踪id 等 业务标识需要输出 业务标识字段的时候，使用MDC配置 bizId字段。注意： MDC 的实现是通过 ThreadLocal&lt;Map&lt;String,String&gt;&gt;实现的,具体可是查阅 ch.qos.logback.classic.util.LogbackMDCAdapter 源码，所以要注意 MDC中字段的更新问题，在多线程环境中尤其要注意线程中的任务执行完毕的时候记得 调用 MDC.clear()方法清理。如上配置可达到以下效果2020-06-01 15:34:19.630 [zl-platform][bizId:bizExample][main] INFO com.jizhang.testlog.TestlogApplication [trackId:trackExample] - info message!!!2020-06-01 15:34:19.630 [zl-platform][bizId:bizExample][main] ERROR com.jizhang.testlog.TestlogApplication [trackId:trackExample] - error message!!!!2020-06-01 15:34:19.633 [zl-platform][bizId:bizExample][main] ERROR com.jizhang.testlog.TestlogApplication [trackId:trackExample] - java.lang.Exception: messages!!!,exception!参考 Java日志记录最佳实践 优秀日志实践准则Nginx 日志规范日志格式Nginx 日志格式统一为一下格式：log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"' 'rt=$request_time uct=\"$upstream_connect_time\" uht=\"$upstream_header_time\" urt=\"$upstream_response_time\"';以上格式在默认格式的基础上添加了反向代理的转发相关信息，供排查问题用。目录格式Nginx 默认日志目录为 /var/log/nginx， 反向代理的服务目录 日志目录无需设置，在默认目录下会有相关文件夹。参考 Nginx 官方 如何建设高吞吐量的日志平台 Logstash Alternatives日志收集考虑到目前日志主要用于 ES 分析，暂定方案为 fileBeats 收集各个系统的日志（包括nginx），统一汇总到logstash 平台然后过滤分析到 ES搜索/kibana分析" }, { "title": "日志收集", "url": "/posts/how-to-collect-log/", "categories": "笔记", "tags": "总结", "date": "2020-07-02 01:00:00 +0800", "snippet": "logstash 缺点： 性能问题 具体 benchmark 可以参考链接 不支持缓存，典型的替代方案还得依赖 kafka 或者Redis 作为中心缓存池 FlumeFlume基于流式数据的、使用简单的（借助配置文件即可）、健壮的、容错的。Flume的简单体现在：写一个source、channel、sink之后，一条命令就能操作成功。Flume、Kaf...", "content": "logstash 缺点： 性能问题 具体 benchmark 可以参考链接 不支持缓存，典型的替代方案还得依赖 kafka 或者Redis 作为中心缓存池 FlumeFlume基于流式数据的、使用简单的（借助配置文件即可）、健壮的、容错的。Flume的简单体现在：写一个source、channel、sink之后，一条命令就能操作成功。Flume、Kafka实时进行数据收集，Storm、Spark实时数据处理，Impala实时查询。 实现方式监控文件 -&gt; 产生事件 -&gt; 发送到channel -&gt; 发送到 sink -&gt; HDFS 优点： 可恢复性强 与 kafka 类似，不过不是消息队列，是一种管道流的方式，提供了很多默认的实现，配几个参数就可以用 Flume采集数据到Kafka：自定义Flume的sink组件，将数据从channel中取出，通过kafka的producer写入到Kafka中，可以自定义分区。 可以直接保存到 HBase 缺点 如果数据要被发送到多个 系统消费的化就必须用 kafka 不能用 flume了 filebeatFilebeat 是一个轻量级的日志传输工具，它的存在正弥补了 Logstash 的缺点：Filebeat 作为一个轻量级的日志传输工具可以将日志推送到中心 Logstash。 实现方式 优点 轻量级，不吃资源 缺点 不解析日志，需要 ES 自己解析日志 日志格式可能需要 存成 json 应用场景 1. 日志直接发送到 ES 2. 日志过滤发送到 kafka 或者 redisLogagentLogagent 是 Sematext 提供的传输工具，它用来将日志传输到 Logsene（一个基于 SaaS 平台的 Elasticsearch API），因为 Logsene 会暴露 Elasticsearch API，所以 Logagent 可以很容易将数据推送到 Elasticsearch 。 优点 可以获取 /var/log 下的所有信息，解析各种格式（Elasticsearch，Solr，MongoDB，Apache HTTPD等等），它可以掩盖敏感的数据信息，例如，个人验证信息（PII），出生年月日，信用卡号码，等等。它还可以基于 IP 做 GeoIP 丰富地理位置信息（例如，access logs）。同样，它轻量又快速，可以将其置入任何日志块中。在新的 2.0 版本中，它以第三方 node.js 模块化方式增加了支持对输入输出的处理插件。重要的是 Logagent 有本地缓冲，所以不像 Logstash ，在数据传输目的地不可用时会丢失日志。 尽管 Logagent 有些比较有意思的功能（例如，接收 Heroku 或 CloudFoundry 日志），但是它并没有 Logstash 灵活。 应用场景 Logagent 作为一个可以做所有事情的传输工具是值得选择的（提取、解析、缓冲和传输）。 rsyslog 绝大多数 Linux 发布版本默认的 syslog 守护进程，rsyslog 可以做的不仅仅是将日志从 syslog socket 读取并写入 /var/log/messages 。它可以提取文件、解析、缓冲（磁盘和内存）以及将它们传输到多个目的地，包括 Elasticsearch 。可以从此处找到如何处理 Apache 以及系统日志。 优点 性能好 各个平台都有 syslog 的 支持，比如 java 的logback 可以执行 syslog 的appender 解析的规则可以很多，但不影响性能 缺点 配置难 应用场景 rsyslog 适合那些非常轻的应用（应用，小VM，Docker容器）。如果需要在另一个传输工具（例如，Logstash）中进行处理，可以直接通过 TCP 转发 JSON ，或者连接 Kafka/Redis 缓冲。 rsyslog 还适合我们对性能有着非常严格的要求时，特别是在有多个解析规则时。那么这就值得为之投入更多的时间研究它的配置。 初步方案 nginx， docker 等 日志直接 用 filebeat 发送到 ES java 日志 用 syslog 的方式 发送到 logstash" }, { "title": "Flink app 部署", "url": "/posts/Flink-deploy/", "categories": "大数据, Flink", "tags": "笔记", "date": "2020-06-13 01:00:00 +0800", "snippet": "部署前检查工作 显式设置最大并行度 给所有的 operator 设置 uuid (如果 对 state 敏感的话) 设置 正确的状态储存后端，避免用 MemoryStateBackend FsStateBackend or RocksDBStateBackend 配置 JobManager 高可用 Standalone Cluster HA or YARN Clust...", "content": "部署前检查工作 显式设置最大并行度 给所有的 operator 设置 uuid (如果 对 state 敏感的话) 设置 正确的状态储存后端，避免用 MemoryStateBackend FsStateBackend or RocksDBStateBackend 配置 JobManager 高可用 Standalone Cluster HA or YARN Cluster HAstandalone环境配置ssh两台机器 master.jizhang.com dev-1.jizhang.com互相配置 ssh 免密登录并添加 hostsjava以下两种方式二选一 配置 JAVA_HOME conf/flink-conf.yaml 中 配置 env.java.homeflink 设置必须 conf/flink-conf.yml 中 jobmanager.rpc.address: master # 设置为 master 节点 host conf/masters 中 master:8081 conf/workers 中 masterdev-1 可选 jobmanager.rpc.port: 6123jobmanager.heap.size: 1024m # 设置jvm heap 大小taskmanager.memory.process.size: 1568mtaskmanager.numberOfTaskSlots: 3 # 设置 taskmanager 中 的 task slot 影响并行 task 数量 一般为 cpu 的数量，可根据 task 的具体情况而定。parallelism.default: 3 # 同上 相同配置文件 从 master 节点 copy 到 其他节点启动和停止bin/start-cluster.sh # 启动bin/stop-cluster.sh # 停止Job manager 高可用待添加###" }, { "title": "REHL Linux 服务器设置免密登录", "url": "/posts/Set_SSH_NO_Password/", "categories": "Linux", "tags": "笔记", "date": "2020-06-12 01:00:00 +0800", "snippet": "环境 Red Hat Enterprise Linux 8 Red Hat Enterprise Linux 7 Red Hat Enterprise Linux 6 Red Hat Enterprise Linux 5方法步骤 生成 SSH key如果你还没有生成过 ssh-key，参照下面的步骤生成一对 ssh-key，如果已经生成直接跳过 [user@ssh-clien...", "content": "环境 Red Hat Enterprise Linux 8 Red Hat Enterprise Linux 7 Red Hat Enterprise Linux 6 Red Hat Enterprise Linux 5方法步骤 生成 SSH key如果你还没有生成过 ssh-key，参照下面的步骤生成一对 ssh-key，如果已经生成直接跳过 [user@ssh-client.example.com ~]$ ssh-keygen -t ecdsaGenerating public/private ecdsa key pair.Enter file in which to save the key (/home/user/.ssh/id_ecdsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /home/user/.ssh/id_ecdsa.Your public key has been saved in /home/user/.ssh/id_ecdsa.pub.The key fingerprint is:SHA256:Q/x+qms4j7PCQ0qFd09iZEFHA+SqwBKRNaU72oZfaCI user@ssh-client.example.comThe key's randomart image is:+---[ECDSA 256]---+|.oo..o=++ ||.. o .oo . ||. .. o. o ||....o.+... ||o.oo.o +S . ||.=.+. .o ||E.*+. . . . ||.=..+ +.. o || . oo*+o. |+----[SHA256]-----+ 复制公钥(Public Key) 到服务器的用户账户中选择下面几种方法的任意一种即可。 注意： 公钥文件名称可能和你的不一样。 用 ssh-copy-id linux 环境 前提是你已经有服务器 ssh 登录的密码了，并且openssh-clients package 已经按照到服务器了，可以通过以下方式将上一步生成的公钥安装到服务器中。 [user@ssh-client.example.com ~]$ ssh-copy-id -i ~/.ssh/id_ecdsa.pub user@ssh-server.example.com user@ssh-server's password: 用ssh 和 cat命令 linxu 环境和 windows 环境都可以用。 [user@ssh-client.example.com ~]$ cat ~/.ssh/id_ecdsa.pub | ssh user@ssh-server.example.com \"cat &gt;&gt; ~/.ssh/authorized_keys\" 以上代码访问了你本地的 .ssh目录，并且复制到了服务器的 authorized_keys 文件中。 手动复制 不推荐 如果你可以登录服务器的 terminal，你可以直接用编辑器编辑 ~/.ssh/authorized_keys 文件，并且把你的本地公钥内容添加到文件中。 比如以下这样： 没有添加之前 Host(ssh-client.example.com) [user@ssh-client.example.com ~]# cat ~/.ssh/authorized_keys ecdsa-sha2-nistp256 BBBBBE2VjZHNhLXNoYTItbmlzdHAyNTYBBBBIbmlzdH1111AAABBBFIv/yAbGAnT1qi2MEsLTAAB8v+YJfJoarEV8uUuKaVEnKyR/FblcI/lbwZ3pqxfalqNuqxQJHhAaJuJkE0jlnI= user@ssh-client.example.com Host(ssh-server.example.com) [user@ssh-server.example.com ~]# cat ~/.ssh/authorized_keys ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdH1111AAABBBFIv/yAbGAnT1qi2MEsLTAAB8v+YJfJoarEV8uUuKaVEnKyR/FblcI/lbwZ3pqxfalqNuqxQJHhAaJuJkE0jlnI= user1@example-1.com 添加之后 Host (ssh-server.example.com) [root@ssh-server.example.com ~]# cat ~/.ssh/authorized_keys ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdH1111AAABBBFIv/yAbGAnT1qi2MEsLTAAB8v+YJfJoarEV8uUuKaVEnKyR/FblcI/lbwZ3pqxfalqNuqxQJHhAaJuJkE0jlnI= user1@example-1.com ecdsa-sha2-nistp256 BBBBBE2VjZHNhLXNoYTItbmlzdHAyNTYBBBBIbmlzdH1111AAABBBFIv/yAbGAnT1qi2MEsLTAAB8v+YJfJoarEV8uUuKaVEnKyR/FblcI/lbwZ3pqxfalqNuqxQJHhAaJuJkE0jlnI= user@ssh-client.example.com 尝试登录现在尝试登录一下服务器，检查一下是否还需要密码 [user@ssh-client.example.com ~]$ ssh user@ssh-server.example.com 问题解决 文件权限问题确保文件权限是以下权限 [user@ssh-server.example.com ~]$ ls -ld ~/{,.ssh,.ssh/authorized_keys*}drwx------. 25 user user 4096 Aug 21 11:01 /home/user/drwx------. 2 user user 4096 Aug 17 13:13 /home/user/.ssh-rw-------. 1 user user 420 Aug 17 13:13 /home/user/.ssh/authorized_keys 如果文件权限不对，用以下命令解决 [user@ssh-server.example.com ~]$ chmod 600 ~/.ssh/authorized_keys[user@ssh-server.example.com ~]$ chmod 700 ~/.ssh/ 另外一种替代办法是关闭 sshd服务的StrictModes,可以修改配置文件/etc/ssh/sshd_config 变成以下内容 StrictModes no 随后，通过sudo systemctl restart sshd 来重启 sshd服务，让配置文件生效。 SELinux 设置SELinux 可以拒绝sshd服务访问 ~/.ssh目录。通过以下命令解决 [user@ssh-server.example.com ~]$ restorecon -Rv ~/.ssh 打开服务器 sshd 服务的RSA认证。确保/etc/ssh/sshd_config 文件中的以下配置没有被注释 RSAAuthentication yesPubkeyAuthentication yes 并且，关闭密码认证 PasswordAuthentication no,之后重新启动sshd 服务 经过以上步骤，应该可以免密登录服务器了。" }, { "title": "MySQL python 驱动 选择", "url": "/posts/Mysql-Python-driver-info/", "categories": "Python", "tags": "笔记", "date": "2020-06-12 01:00:00 +0800", "snippet": "因为 python 总所周知的历史原因，有很多包可以选择，这边一句话总结一下，希望有帮助python2MySQL-Pythonmysql-python 是 python2 时代的连接mysql 的package，底层用C 实现，用python 包装成 python package,安装的时候需要编译，也可以下载二进制文件进行安装，但是需要注意的是： mysql-python 只 支持 myq...", "content": "因为 python 总所周知的历史原因，有很多包可以选择，这边一句话总结一下，希望有帮助python2MySQL-Pythonmysql-python 是 python2 时代的连接mysql 的package，底层用C 实现，用python 包装成 python package,安装的时候需要编译，也可以下载二进制文件进行安装，但是需要注意的是： mysql-python 只 支持 myqsl 3.23- 5.5 的版本和python 2.4-2.7版本，如果有历史项目无法迁移的，时候需要注意。mysql-connector-pythonmysql-connector-python 是oracle 收购 mysql 之后为了解决python mysql adapter 混乱的问题开发的一个package，用纯python 实现，性能没有 mysql-python 好，但是优点是 支持很广泛，从python2 到3 都可以，也支持连接池，线程安全，属于可靠的类别python3mysqlclientmysqlclient 是 mysql-python 的一个 mysqldb1分支的的clone 版本，在 msyqldb1 的基础上 开发了支持 python3 的版本，并且兼容之前的mysql-python。不同的python 版本 和 mysql 版本可以下载不同的版本支持。pymysql跟 mysql-connector-python 一样是个 纯python 实现的adapter，但是存在线程安全的问题，并且不支持连接池。属于历史的眼泪了，基本上已经不更新了。参考 django 官方 知乎 跑分 stackoverflow" }, { "title": "HUE 简单部署", "url": "/posts/HUE-install-deploy/", "categories": "大数据", "tags": "笔记", "date": "2020-06-04 01:00:00 +0800", "snippet": "部署 docker 镜像拉取 docker pull gethue/hue:latest 启动命令 docker run -d -p 8888:8888 -v /usr/share/hue/desktop/conf:/usr/share/hue/desktop/conf --name hue --restart always gethue/hue:latest ...", "content": "部署 docker 镜像拉取 docker pull gethue/hue:latest 启动命令 docker run -d -p 8888:8888 -v /usr/share/hue/desktop/conf:/usr/share/hue/desktop/conf --name hue --restart always gethue/hue:latest 说明： 挂载 desktop/conf 中的 hue.ini 文件到 宿主机目录下，可以很方便的修改配置文件并 重启： docker container restart hue 配置hue 数据库：修改 /desktop/conf/hue.ini 配置文件中 database 配置为如下配置：engine=mysqlhost=192.168.2.99port=3306user=rootpassword=BOOT-xwork1024name=hue添加数据源Mysql /desktop/conf/hue.ini 配置文件中 librdbms.databases 模块中添加如下配置： [[[mysql]]] # Name to show in the UI. nice_name=\"99MySQL\" # name=spider engine=mysql host=192.168.2.99 port=3306 user=root password=BOOT-xwork1024 options={\"charset\":\"utf8mb4\"} # 解决中文乱码 notebook.interpreters 中添加如下配置 [[[mysql]]] name = 99MySQL interface=rdbms Hbase待添加hive待添加权限设置hue 的权限用的是 django 框架的权限模块，也web 页面上可以设置 组权限，并将响应的用户添加到组中。" }, { "title": "Hadoop standalone 安装笔记", "url": "/posts/Hadoop-install/", "categories": "大数据", "tags": "笔记", "date": "2020-06-03 01:00:00 +0800", "snippet": "服务器ip: 192.168.2.106usr: zlpassword: 123456hadoop 伪集群模式安装版本选择最新版是 3.3 版本，但是考虑到各个组件的兼容性问题 选择2.10 版本的hadoop安装 根据附录下载 相关文件 解压 tar -zxvf hadoop-2.10.0.tar.gz 配置 hadoop 相关命令到系统path 中 ech...", "content": "服务器ip: 192.168.2.106usr: zlpassword: 123456hadoop 伪集群模式安装版本选择最新版是 3.3 版本，但是考虑到各个组件的兼容性问题 选择2.10 版本的hadoop安装 根据附录下载 相关文件 解压 tar -zxvf hadoop-2.10.0.tar.gz 配置 hadoop 相关命令到系统path 中 echo \"export HADOOP_HOME=/home/zl/hadoop-2.10.0\" &gt;&gt; ~/.bashrc &amp;&amp;echo \"PATH=\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin:\\$PATH\" &gt;&gt; ~/.bashrc &amp;&amp;source ~/.bashrc 配置 JAVA_HOME 环境变量命令 略 测试一下命令，验证安装是否正常 hadoop 配置 hdfs 伪集群模式 ${HADOOP_HOME}/etc/hadoop/core-site.xml 中添加: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt; dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/zl/hadoop-data/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/home/zl/hadoop-data/datanode&lt;/value&gt; &lt;property&gt; &lt;/configuration&gt; 配置 ssh ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa &amp;&amp; cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; chmod 0600 ~/.ssh/authorized_keys 启动hdfs 执行 格式化 hdfs bin/hdfs namenode -format 启动 sbin/start-dfs.sh 关闭 sbin/stop-dfs.sh root 用户启动需要设置 环境变量export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root配置 yarn 伪集群模式 ${HADOOP_HOME}/etc/hadoop/mapred-site.xml 中添加 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; ${HADOOP_HOME}/etc/hadoop/yarn-site.xml 中添加 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 启动 start-yarn.sh 关闭 stop-yarn.sh web 页面： http://localhost:8088/ web 端口 组件 配置 默认值 NameNode http://nn_host:port/ Default HTTP port is 50070. ResourceManager http://rm_host:port/ Default HTTP port is 8088. MapReduce JobHistory Server http://jhs_host:port/\tDefault HTTP port is 19888. Hbase 安装 (Pseudo-distributed)版本选择最新版 2.3.0安装 解压 tar -zxvf hbase-2.3.0-bin.tar.gz 配置 java_home 略 配置 PATH echo \"export HBASE_HOME=/home/zl/hbase-2.3.0\" &gt;&gt; ~/.bashrc &amp;&amp;echo \"PATH=\\$HBASE_HOME/bin:\\$PATH\" &gt;&gt; ~/.bashrc &amp;&amp;source ~/.bashrc 配置 hbase 伪集群 conf/hbase-site.xml 中添加 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 启动 hbase bin/start-hbase.sh web 页面访问 http://localhost:16010sqoop 导入相关依赖用 sqoop 导入 包 版本 依赖 hadoop 2.x hbase 2.x hbase-client 1.12.x metrics-core 2.2.0jar 包 放到 sqoop lib 中参考 链接 https://www.cnblogs.com/jdbc-mydql/p/8489961.html附：相关链接 hadoop-doc hadoop 2.10 安装包 Hbase 2.2.5 安装包 " }, { "title": "Optimizing Kafka consumers (kafka consumers(消费者)调优)(翻译)", "url": "/posts/Kafka-Optimize/", "categories": "中间件", "tags": "翻译学习, 挖坑", "date": "2020-06-02 01:00:00 +0800", "snippet": "原文引言上篇《微调 Kafka 生产者》文章中，我们给出了几点可以改进 Kafka 生产端的建议。这篇文章我们将要来检视几个调优 kafka 消费端的常用选择。在流式系统中，是非常值得考虑传输两端的性能的。如果你让你的生产端的效率提升了，相应的消费端也需要提升效率来适应。最起码不能让消费端成为性能瓶颈。正如我们接下来要介绍的内容一样，一些消费端的配置实际上依赖其生产段和 部分kafka 的通...", "content": "原文引言上篇《微调 Kafka 生产者》文章中，我们给出了几点可以改进 Kafka 生产端的建议。这篇文章我们将要来检视几个调优 kafka 消费端的常用选择。在流式系统中，是非常值得考虑传输两端的性能的。如果你让你的生产端的效率提升了，相应的消费端也需要提升效率来适应。最起码不能让消费端成为性能瓶颈。正如我们接下来要介绍的内容一样，一些消费端的配置实际上依赖其生产段和 部分kafka 的通用配置。如何观察 kafka 消费端的性能在寻求优化您的消费者时，您当然希望控制在失败时消息会发生什么。 而且您还需要尽可能确保您已经适当地扩展了您的消费者组以处理您期望的吞吐量水平。 与生产者一样，您需要在开始进行调整之前监控消费者的表现。 从可靠性和稳定性方面考虑您对消费者的期望。当我们试图调优消费端的时候，首先需要做的肯定是想要控制消息消费失败时做了什么。其次才需要尽可能的增加消费组的数量来让吞吐量尽可能的增大以适应业务。跟生产者一样，我们也需要手机消费端的性能指标数据用来比较调整参数之后的变化。可以先查阅 kafka 的 Fetch Metrics 来确定我们需要检测的指标。消费者基础配置消费端的基础配置首先必须有 host:port形式的 bootstrap server 地址用来链接 kafka broker。其次需要有传入一个 deserializers 策略来转换 消息keys 和 values。 client.id 可选，用来标记clientbootstrap.servers=localhost:9092key.deserializer=org.apache.kafka.common.serialization.StringDeserializervalue.deserializer=org.apache.kafka.common.serialization.StringDeserializerclient.id=my-client关键配置On top of our minimum configuration, there are a number of properties you can use to fine-tune your consumer configuration. We won’t cover all possible consumer configuration options here, but examine a curated set of properties that offer specific solutions to requirements that often need addressing: group.id fetch.max.wait.ms fetch.min.bytes fetch.max.bytes max.partition.fetch.bytes max.message.bytes (topic or broker) enable.auto.commit enable.commit.interval.ms isolation.level session.timeout.ms heartbeat.interval.ms auto.offset.reset group.instance.id max.poll.interval.ms max.poll.records" }, { "title": "CDH 平台安装笔记", "url": "/posts/CDH-install/", "categories": "大数据", "tags": "笔记", "date": "2020-06-02 01:00:00 +0800", "snippet": "集群准备物理机配置cpu: core:10 * 4内存： 16G硬盘： 1T安装 vmware esxi 虚拟机平台参考esxi 安装虚拟机所有选择 centos7 最小安装版本 主机名 cpu 内存 硬盘 master 8 6G 300G slave...", "content": "集群准备物理机配置cpu: core:10 * 4内存： 16G硬盘： 1T安装 vmware esxi 虚拟机平台参考esxi 安装虚拟机所有选择 centos7 最小安装版本 主机名 cpu 内存 硬盘 master 8 6G 300G slave-1 8 4G 100G slave-2 8 4G 100G 安装 CDH安装前准备 更改hostname 更改host name106、107、108 上都添加如下host 192.168.2.106 master.jizhang.com master 192.168.2.107 slave-1.jizhang.com slave-1 192.168.2.108 slave-2.jizhang.com slave-2 106 上执行 hostnamectl set-hostname master.jizhang.com107 上执行 hostnamectl set-hostname slave-1.jizhang.com108 上执行 hostnamectl set-hostname slave-2.jizhang.com 分别 编辑 /etc/sysconfig/network 为以下内容 HOSTNAME=master/slave-1/slave-2.jizhang.com # 只需要写 master 或者slave 验证hostname 执行 host -v -t A $(hostname) （报错安装 yum install bind-utils）,查看是否为 对应的hostname uname -a 中是否有 对应的hostname 关闭防火墙 centos 执行 sudo systemctl disable firewalld &amp;&amp; sudo systemctl stop firewalld 设置 SELinux 模式 执行命令 getenforce 如果输出是 Enforcing,继续，否则跳过 打开文件 /etc/selinux/config中设置 SELINUX=permissive，保存退出 重启服务器，并执行命令setenforce 0 CDH 安装完成可以重新把 SELINUX=permissiveg改回SELINUX=Enforcing并执行命令setenforce 1重新激活Enforcing模式 设置 NTP SERVER centos 默认安装好了就配置好了，需要配置 参考官方文档 安装 CM 下载 CM repo 文件 执行 sudo wget https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/ import repo 下面的 username 和 password 在 cdh 官网注册一个 sudo rpm --import https://username:password@archive.cloudera.com/p/cm6/6.3.3/redhat7/yum/RPM-GPG-KEY-cloudera CM 数据库迁移CM 自带 PostgreSQL 数据库，需要从PostgreSQL 数据库迁移到 mysql 数据，常用命令sudo service cloudera-scm-agent stop #停止 agentsudo service cloudera-scm-server stop #停止 web 页面service cloudera-scm-server-db stop #停止 内置 dbsudo systemctl stop supervisord" }, { "title": "Windows 系统安装软件清单", "url": "/posts/MySofteware/", "categories": "生活", "tags": "备份", "date": "2018-09-01 00:00:00 +0800", "snippet": "新系统需要安装 常用软件 Chrome Office 系列 Adobe pdf 火绒: 安静的一批。 Revo Uninstaller 2021年2月更新，已经不在乎卸载垃圾了 TeXstudio update: VS code 无敌~ Everything 社交软件 微信 ...", "content": "新系统需要安装 常用软件 Chrome Office 系列 Adobe pdf 火绒: 安静的一批。 Revo Uninstaller 2021年2月更新，已经不在乎卸载垃圾了 TeXstudio update: VS code 无敌~ Everything 社交软件 微信 钉钉 QQ 开发环境搭建 Python JAVA IDEA,PyCharm,Vscode Postman Xshell 系列 数据库相关软件 下载软件 迅雷极速版，IDM " } ]
